['train', 'tip', 'transform', 'model', 'martin', 'popel', 'ondrej', 'bojar', 'charl', 'univers', 'faculti', 'mathemat', 'physic', 'institut', 'formal', 'appli', 'linguist', 'pragu', 'czechia', 'abstract', 'thi', 'articl', 'describ', 'our', 'experi', 'neural', 'machin', 'translat', 'use', 'recent', 'ten', 'sortensorframeworkandthetransformersequencetosequencemodel', 'vaswaniet', 'examin', 'some', 'critic', 'paramet', 'that', 'ect', 'nal', 'translat', 'qualiti', 'memori', 'usag', 'train', 'stabil', 'train', 'time', 'conclud', 'each', 'experi', 'with', 'set', 'recom', 'mendat', 'fellow', 'research', 'addit', 'con', 'rming', 'gener', 'mantra', 'more', 'data', 'larger', 'model', 'address', 'scale', 'multipl', 'gpu', 'provid', 'practic', 'tip', 'im', 'prove', 'train', 'regard', 'batch', 'size', 'learn', 'rate', 'warmup', 'step', 'maximum', 'sentenc', 'length', 'andcheckpointaverag', 'wehopethatourobservationswillallowotherstogetbetterresult', 'given', 'their', 'particular', 'hardwar', 'data', 'constraint', '1', 'introduct', 'it', 'been', 'alreadi', 'clearli', 'establish', 'that', 'neural', 'machin', 'translat', 'nmt', 'new', 'state', 'art', 'machin', 'translat', 'see', 'eg', 'most', 'recent', 'evalu', 'campaign', 'bojaretala', 'cettoloet', 'manyfundamentalchangesofth', 'underli', 'neural', 'network', 'architectur', 'nevertheless', 'still', 'frequent', 'it', 'veri', 'di', 'cult', 'predict', 'which', 'architectur', 'best', 'combin', 'properti', 'towininthelongterm', 'consideringallrelevantcriterialiketranslationqu', 'model', 'size', 'stabil', 'speed', 'train', 'interpret', 'but', 'also', 'practic', 'avail', 'goodimplement', 'aconsiderablepartofamodel', 'ssuccessintranslationqu', 'consist', 'train', 'data', 'model', 's', 'sensit', 'nois', 'data', 'but', 'also', 'wide', 'rang', 'hyperparamet', 'that', 'ect', 'train', 'have', 'right', 'set', 'them', 'turn', 'out', 'often', 'critic', 'compon', 'success', 'arxivv', 'cscl', '2', 'may', 'inthisarticl', 'weexperimentwitharelativelynewnmtmodel', 'calledtransform', 'vaswaniet', 'asimplementedinthetensortensor', 'onesuperior', 'abbreviatedtt', 'toolkit', 'version', 'themodelandthetoolkithavebeenreleasedshortlyaftertheevalu', 'campaignatwmt', 'twosuperioranditsbehavioronlargedatanewstranslationisnotyet', 'explor', 'want', 'empir', 'explor', 'some', 'import', 'hyperparamet', 'hope', 'our', 'observ', 'will', 'use', 'also', 'other', 'research', 'consid', 'thi', 'model', 'framework', 'whileinvestigationsintothe', 'ectofhyperparameterslikelearningrateandbatch', 'sizeareavailableinthedeeplearningcommun', 'egbottouet', 'smithand', 'le', '2017', 'jastrzebski', 'et', 'al', '2017', 'these', 'either', 'mostli', 'theoret', 'or', 'experiment', 'support', 'from', 'domain', 'like', 'imag', 'recognit', 'rather', 'than', 'machin', 'translat', 'thi', 'articl', 'll', 'gap', 'by', 'focus', 'exclus', 'mt', 'transform', 'model', 'onli', 'provid', 'hope', 'best', 'practic', 'thi', 'particular', 'set', 'some', 'our', 'observ', 'con', 'rm', 'gener', 'wisdom', 'eg', 'larger', 'train', 'data', 'aregenerallybett', 'andquantifythebehavioronenglishtoczechtranslationexp', 'iment', 'some', 'our', 'observ', 'somewhat', 'surpris', 'eg', 'that', 'two', 'gpu', 'more', 'than', 'three', 'time', 'faster', 'than', 'singl', 'gpu', 'or', 'our', 'nding', 'about', 'interact', 'between', 'maximum', 'sentenc', 'length', 'learn', 'rate', 'batch', 'size', 'thearticleisstructuredasfollow', 'insect', 'wediscussourevaluationmethod', 'ologyandmaincriteria', 'translationqualityandspeedoftrain', 'sectiondescrib', 'our', 'dataset', 'it', 'prepar', 'section', '4', 'main', 'contribut', 'articl', 'set', 'comment', 'experi', 'each', 'with', 'set', 'recommend', 'final', 'sec', 'tioncomparesourbesttransformerrunwithsystemsparticipatinginwmt', 'conclud', 'section', '6', '2', 'evalu', 'methodolog', 'machin', 'translat', 'evalu', 'mani', 'way', 'some', 'form', 'human', 'judgment', 'should', 'alway', 'use', 'ultim', 'resolut', 'ani', 'nal', 'applic', 'thecommonpracticeinmtresearchistoevaluatethemodelperformanceonatestset', 'against', 'one', 'or', 'more', 'human', 'refer', 'translat', 'most', 'widespread', 'automat', 'metricisundoubtedlythebleuscor', 'papineniet', 'despiteitsacknowledg', 'problem', 'betterperform', 'altern', 'bojar', 'et', 'al', 'b', 'simplic', 'stick', 'bleu', 'too', 'evalu', 'our', 'result', 'also', 'with', 'cschscrscf', 'popov', '2015', 'but', 'foundnosubstantialdi', 'erencesfrombleu', 'inparticular', 'weusethecaseinsensit', 'sacrbleu', 'threesuperiorwhich', 'use', 'xed', 'token', 'ident', 'mtevalvpl', 'interna', 'onesuperiorhttp', 'githubcomtensorflowtensortensor', 'twosuperiorhttp', 'wwwstatmtorgwmt', 'threesuperiorhttp', 'githubcomawslabssockeyetreemastercontribsacrebleu', 'signatur', 'bleu', 'score', 'report', 'thi', 'paper', 'bleucaselclangencsnumrefssmooth', 'exptestwmttokintlvers', 'tionaltoken', 'automat', 'download', 'refer', 'translat', 'given', 'wmt', 'testset', '21', 'consider', 'stop', 'criterion', 'situat', 'nmt', 'further', 'complic', 'by', 'fact', 'that', 'train', 'nmt', 'systemsisusuallynondeterminist', 'esp', 'withthemostrecentmodel', 'hardli', 'everconvergesorstartsov', 'tting', 'onreasonablybigdataset', 'thisleadstolearn', 'curvesthatnev', 'attenletalonestartdecreas', 'seesect', 'thecommon', 'practic', 'machin', 'learn', 'evalu', 'model', 'nal', 'test', 'set', 'when', 'it', 'start', 'over', 'tting', 'or', 'bit', 'sooner', 'thu', 'not', 'applic', 'practic', 'mani', 'paper', 'neural', 'machin', 'translat', 'not', 'specifi', 'ani', 'stop', 'criteria', 'whatsoev', 'sometim', 'theymentiononlyanapproximatenumberofdaysthemodel', 'wa', 'train', 'eg', 'bahdanau', 'et', 'al', '2015', 'sometim', 'exact', 'number', 'train', 'step', 'given', 'but', 'indic', 'how', 'much', 'converg', 'model', 'wa', 'that', 'point', 'eg', 'vaswaniet', '2017', 'mostprob', 'thetrainingwasrununtilnofurth', 'improvementswereclearlyapparentonthedevelopmenttestset', 'andthemodelwa', 'evalu', 'that', 'point', 'such', 'an', 'approxim', 'stop', 'criterion', 'rather', 'riski', 'it', 'conceivablethatdi', 'erentsetupswerestoppedatdi', 'erentstagesoftrainingandtheir', 'comparison', 'not', 'fair', 'somewhat', 'more', 'reliabl', 'method', 'keep', 'train', 'speci', 'ed', 'number', 'iter', 'or', 'certain', 'number', 'epoch', 'thi', 'howev', 'not', 'perfect', 'solut', 'either', 'if', 'model', 'not', 'quit', 'converg', 'that', 'time', 'di', 'erenc', 'their', 'perform', 'not', 'su', 'cientli', 'larg', 'it', 'quit', 'possibl', 'that', 'eg', 'more', 'complex', 'model', 'would', 'need', 'few', 'more', 'epoch', 'eventu', 'arriv', 'higher', 'score', 'than', 'it', 'competitor', 'also', 'durat', 'one', 'train', 'step', 'or', 'one', 'epoch', 'di', 'er', 'between', 'model', 'seesect', 'andfromthepracticalpointofview', 'wearemostlyinterest', 'wallclock', 'time', 'when', 'tri', 'standard', 'techniqu', 'earli', 'stop', 'when', 'nsubsequ', 'evaluationsonthedevelopmenttestsetdonotgiveimprovementslargerthanagiven', 'delta', 'wesawabigvarianceinthetrainingtimeand', 'nalbleu', 'evenforexperi', 'with', 'same', 'hyperparamet', 'just', 'di', 'erent', 'random', 'seed', 'moreov', 'get', 'best', 'result', 'would', 'use', 'veri', 'larg', 'nand', 'veri', 'small', 'delta', 'evenifw', 'xtherandomse', 'whichwasnotdoneproperlyinttv', 'achangeofsomehyp', 'paramet', 'may', 'ect', 'result', 'not', 'becaus', 'chang', 'itself', 'but', 'becaus', 'it', 'uenc', 'random', 'initi', 'by', 'over', 'tting', 'mean', 'here', 'that', 'translat', 'qualiti', 'testset', 'bleu', 'begin', 'worsen', 'while', 'train', 'loss', 'keep', 'improv', '322', 'our', 'final', 'choic', 'full', 'learn', 'curv', 'basedonthediscussionabov', 'wedecidedtoreportalwaysthefulllearningcurv', 'not', 'just', 'singl', 'score', 'thi', 'solut', 'doe', 'not', 'fulli', 'prevent', 'risk', 'prematur', 'judgment', 'butthereaderscanatleastjudgeforthemselvesiftheywouldexpectani', 'sudden', 'twist', 'result', 'or', 'not', 'case', 'plot', 'caseinsensit', 'bleu', 'score', 'against', 'wallclock', 'time', 'hour', 'thi', 'solut', 'obvious', 'depend', 'hardwar', 'chosen', 'so', 'alway', 'usedthesameequip', 'oneuptoeightgeforcegtxtigpuswithnvidia', 'driver', '37566', 'some', 'variat', 'measur', 'unfortun', 'unavoid', 'becaus', 'could', 'not', 'fulli', 'isol', 'comput', 'from', 'di', 'erent', 'process', 'same', 'machin', 'from', 'gener', 'network', 'tra', 'c', 'but', 'base', 'our', 'experi', 'with', 'replic', 'experi', 'such', 'variat', 'neglig', '23', 'terminolog', 'clariti', 'de', 'ne', 'follow', 'term', 'adher', 'them', 'rest', 'paper', 'translat', 'qualiti', 'an', 'automat', 'estim', 'how', 'well', 'translat', 'carri', 'out', 'by', 'particular', 'xed', 'model', 'express', 'mean', 'sourc', 'estim', 'translat', 'qualiti', 'sole', 'by', 'bleu', 'score', 'against', 'one', 'refer', 'translat', 'train', 'step', 'denot', 'number', 'iter', 'ie', 'number', 'time', 'opti', 'mizer', 'updat', 'wa', 'run', 'thi', 'number', 'also', 'equal', 'number', 'mini', 'batch', 'that', 'were', 'process', 'batch', 'size', 'isthenumberoftrainingexamplesusedbyonegpuinonetrainingstep', 'sequencetosequ', 'model', 'batch', 'size', 'usual', 'speci', 'ed', 'number', 'ofsentencepair', 'howev', 'theparamet', 'batchsiz', 'intttranslationspeci', 'es', 'approxim', 'number', 'token', 'subword', 'one', 'batch', 'thi', 'allow', 'use', 'higher', 'number', 'short', 'sentenc', 'one', 'batch', 'or', 'smaller', 'number', 'long', 'sentenc', 'e', 'ectiv', 'batch', 'size', 'number', 'train', 'exampl', 'consum', 'one', 'train', 'step', 'whentrainingonmultiplegpu', 'theparamet', 'batchsiz', 'isinterpret', 'pergputhati', 'with', 'batchsiz', 'andgpu', 'thesystemactuallydigest', 'k', 'subword', 'each', 'languag', 'one', 'step', 'train', 'epoch', 'correspond', 'one', 'complet', 'pass', 'over', 'train', 'data', 'unfortu', 'nate', 'it', 'not', 'easi', 'measur', 'number', 'train', 'epoch', 'tt', 'tt', 'thi', 'purpos', 'number', 'token', 'sentenc', 'de', 'ned', 'maximum', 'sourc', 'target', 'subword', 'ttalsodoesreorderingandbucketingofthesentencesbytheirlengthtominimizetheuseof', 'pad', 'symbol', 'howev', 'some', 'pad', 'still', 'need', 'thu', 'batchsiz', 'onli', 'approxim', 'actual', 'number', 'nonpad', 'subword', 'batch', 'http', 'githubcomtensorflowtensortensorissu', 'report', 'onli', 'number', 'train', 'step', 'order', 'convert', 'train', 'step', 'epoch', 'need', 'multipli', 'step', 'by', 'e', 'ectiv', 'batch', 'size', 'divid', 'by', 'thenumberofsubwordsinthetrainingdata', 'seesect', 'thesegment', 'ofthetrainingdataintosubwordsisusuallyhiddentotheuserandthenumb', 'subword', 'must', 'thu', 'comput', 'by', 'special', 'script', 'comput', 'speed', 'issimplytheobservednumberoftrainingstepsperhour', 'com', 'putat', 'speed', 'obvious', 'depend', 'hardwar', 'gpu', 'speed', 'gpucpu', 'commun', 'softwar', 'driver', 'version', 'cuda', 'librari', 'version', 'impl', 'mentat', 'main', 'paramet', 'ect', 'comput', 'speed', 'model', 'size', 'optimizerandothersettingsthatdirectlymodifytheformulaoftheneur', 'network', 'train', 'throughput', 'amount', 'train', 'data', 'digest', 'by', 'train', 'report', 'train', 'throughput', 'subword', 'per', 'hour', 'train', 'throughput', 'equal', 'comput', 'speed', 'multipli', 'by', 'e', 'ectiv', 'batch', 'size', 'converg', 'speed', 'orbleuconverg', 'istheincreaseinbleudividedbytim', 'converg', 'speed', 'chang', 'heavili', 'dure', 'train', 'start', 'veri', 'high', 'decreas', 'train', 'progress', 'converg', 'model', 'should', 'conver', 'genc', 'speed', 'zero', 'time', 'till', 'score', 'train', 'time', 'need', 'achiev', 'certain', 'level', 'translat', 'qualiti', 'our', 'case', 'bleu', 'use', 'thi', 'an', 'inform', 'measur', 'becaus', 'it', 'not', 'clear', 'how', 'de', 'ne', 'moment', 'achiev', 'given', 'bleu', 'score', 'de', 'ne', 'it', 'time', 'after', 'which', 'bleu', 'never', 'fall', 'below', 'given', 'level', '8', 'exampl', 'till', 'score', 'number', 'train', 'exampl', 'subword', 'need', 'achiev', 'certain', 'level', 'bleu', 'it', 'equal', 'time', 'till', 'score', 'multipli', 'by', 'train', 'throughput', '24', 'tool', 'evalu', 'within', 'tensortensor', 'tt', 'be', 'implement', 'tensorflow', 'provid', 'nice', 'tensorboard', 'visual', 'train', 'progress', 'origin', 'implement', 'wa', 'optim', 'toward', 'speed', 'evalu', 'rather', 'than', 'toward', 'follow', 'standard', 'eld', 'tt', 'thu', 'report', 'approxbleu', 'bydefault', 'whichiscomputedontheinternalsubword', 'never', 'expos', 'user', 'actual', 'instead', 'word', 'accord', 'bleu', 'token', 'result', 'approxbleu', 'usual', 'about', '1218', 'time', 'higher', 'than', 'real', 'bleu', 'due', 'it', 'depend', 'train', 'data', 'subword', 'vocabulari', 'it', 'not', 'easili', 'reproduc', 'vari', 'experi', 'thu', 'not', 'suitabl', 'report', 'public', 'such', 'de', 'nition', 'time', 'till', 'score', 'lead', 'high', 'varianc', 'it', 'valu', 'becaus', 'rel', 'high', 'bleu', 'varianc', 'between', 'subsequ', 'checkpoint', 'visibl', 'icker', 'learn', 'curv', 'gure', 'decreas', 'variat', 'one', 'use', 'bigger', 'develop', 'test', 'set', 'sentenc', 'en', 'word', 'cs', 'word', 'czeng', '17', '57', 'm', '618', 'm', '543', 'm', 'europarlv', '647', 'k', '15', 'm', '13', 'm', 'newscommentaryv', '190', 'k', '41', 'm', '37', 'm', 'commoncrawl', '161', 'k', '33', 'm', '29', 'm', 'total', '58', 'm', '640', 'm', '563', 'm', 'tabl', '1', 'train', 'data', 'resourc', 'weimplementedahelperscript', 'ttbleu', 'whichcomputesth', 'real', 'bleu', 'give', 'same', 'result', 'sacrbleu', 'with', 'token', 'intl', 'our', 'script', 'use', 'two', 'way', 'evalu', 'one', 'translat', 'le', 'ttbleu', 'translationmywmtd', 'referencewmtdeend', 'evalu', 'translat', 'given', 'directori', 'creat', 'eg', 'by', 'tttranslat', 'store', 'result', 'tensorboard', 'event', 'le', 'gure', 'thi', 'articl', 'were', 'creat', 'thi', 'way', 'wealsoimpl', 'tttranslateal', 'ttavgal', 'script', 'whichtransl', 'checkpoint', 'given', 'directori', 'averag', 'window', 'n', 'subsequ', 'check', 'point', 'respect', 'detail', 'averag', 'see', 'section', '410', '3', 'data', 'select', 'preprocess', 'focus', 'englishtoczech', 'translat', 'direct', 'most', 'our', 'train', 'data', 'come', 'from', 'czeng', 'parallel', 'treebank', 'version', '17', 'm', 'sentenc', 'pair', 'onesuperior', 'rest', 'm', 'sentenc', 'pair', 'come', 'from', 'three', 'smaller', 'sourc', 'europarl', 'news', 'commentari', 'common', 'crawl', 'detail', 'tabl', '1', 'use', 'thi', 'dataset', 'm', 'sentenc', 'pair', 'most', 'our', 'experi', 'some', 'experi', 'section', '42', '46', 'substitut', 'czeng', '17', 'with', 'an', 'older', 'consider', 'smaller', 'czeng', '10', 'bojar', 'et', 'al', '2012', 'contain', 'm', 'sentenc', 'pair', 'mm', 'enc', 'word', 'plot', 'perform', 'throughout', 'train', 'use', 'wmt', 'newstest', 'develop', 'set', 'not', 'overlap', 'with', 'train', 'data', 'section', '5', 'appli', 'our', 'best', 'model', 'judg', 'from', 'perform', 'develop', 'set', 'wmt', 'newstest', 'comparison', 'with', 'stateoftheart', 'system', 'three', 'script', 'now', 'mergedin', 'tt', 'master', 'three', 'script', 'use', 'while', 'trainingi', 'still', 'progress', 'ie', 'they', 'wait', 'given', 'number', 'minut', 'new', 'checkpoint', 'appear', 'onesuperiorhttp', 'ufalmffcuniczczengczeng', 'which', 'subset', 'czeng', '16', 'bojar', 'et', 'al', '2016', '631', 'train', 'data', 'preprocess', 'data', 'preprocess', 'such', 'token', 'truecas', 'alway', 'been', 'veri', 'importantpartofthesetupofstatisticalmachinetranslationsystem', 'ahugeleapin', 'scale', 'nmt', 'realist', 'data', 'size', 'been', 'achiev', 'by', 'introduct', 'subword', 'unit', 'sennrichet', 'butthelongtermvisionofthedeeplearningcommun', 'leav', 'these', 'technic', 'train', 'neural', 'network', 'feed', 'it', 'with', 'origin', 'input', 'possibl', 'see', 'eg', 'lee', 'et', 'al', '2016', 'tt', 'adopt', 'thi', 'vision', 'while', 'it', 'support', 'use', 'extern', 'subword', 'unit', 'it', 'come', 'with', 'it', 'own', 'builtin', 'method', 'similar', 'wordpiec', 'algorithm', 'by', 'wu', 'et', 'al', '2016', 'anddoesnotexpecttheinputtobeeventoken', 'basedonasmallsampleof', 'thetrainingdata', 'ttwilltrainasubwordvocabularyandapplyittoallthetrain', 'later', 'evalu', 'data', 'follow', 'tt', 'default', 'provid', 'raw', 'plain', 'text', 'train', 'sentenc', 'use', 'default', 'paramet', 'share', 'sourc', 'target', 'english', 'czech', 'subword', 'vocabulari', 'size', 'k', 'onesuperioronesuperioraft', 'thi', 'preprocess', 'total', 'number', 'subword', 'our', 'main', 'train', 'data', '992', 'million', 'take', 'maximum', 'english', 'czech', 'length', 'each', 'sentenc', 'pair', 'need', 'comput', 'number', 'epoch', 'see', 'section', '23', 'smaller', 'dataset', 'czeng', '10', '327', 'million', 'subword', 'both', 'case', 'averag', 'number', 'subword', 'per', 'spacedelimit', 'word', 'about', '15', 'evenwhenfollowingthedefault', 'therearesomeimportantdetailsthatshouldb', 'consid', 'thu', 'provid', 'our', 'rst', 'set', 'technic', 'tip', 'here', 'tip', 'train', 'data', 'preprocess', 'makesurethatthesubwordvocabularyistrainedonasu', 'cientlylargesampl', 'train', 'data', 'onesuperiortwosuperior', 'asdiscussedinsect', 'ahigherbatchsizemaybeben', 'cialforthetrain', 'batch', 'size', 'higher', 'when', 'exclud', 'train', 'sentenc', 'longer', 'than', 'given', 'threshold', 'thi', 'control', 'with', 'paramet', 'maxlength', 'see', 'section', 'butitmaybeagoodideatoexcludetoolongsentencesevenbefor', 'preparingthetrainingdataus', 'ttdatagen', 'thiswaythetfrecordstrain', 'le', 'will', 'smaller', 'their', 'process', 'bit', 'faster', 'onesuperiorthreesuperior', 'onesuperioronesuperiormoredetailsonttwithbpesubwordunitsbysennrichet', '2016', 'vs', 'theinternalimplement', 'canbefoundinthetechnicalreport', 'morphologicalandlanguageagnosticwordsegmentationfornmt', 'attach', 'deliver', '23', 'project', 'qt', 'http', 'wwwqteuresourc', 'onesuperiortwosuperiorthi', 'control', 'by', 'filebytebudget', 'constant', 'which', 'must', 'chang', 'directli', 'sourc', 'code', 'inttv', 'asignoftoosmalltrainingdataforthesubwordvocabularyisthatth', 'mincount', 'asreport', 'log', 'too', 'low', 'so', 'vocabulari', 'estim', 'from', 'word', 'seen', 'onli', 'or', 'twice', 'onesuperiorthreesuperiorw', 'did', 'such', 'pre', 'ltere', 'our', 'experi', '74', 'experi', 'thi', 'section', 'present', 'sever', 'experi', 'alway', 'summar', 'obser', 'vation', 'give', 'some', 'gener', 'applic', 'tip', 'that', 'learn', 'experi', 'were', 'done', 'with', 'tt', 'v', 'unless', 'state', 'otherwis', 'experi', 'with', 'two', 'set', 'hyperparamet', 'prede', 'ned', 'tt', 'tran', 'formerbigsinglegpu', 'big', 'transformerbasesinglegpu', 'base', 'which', 'di', 'er', 'mainli', 'size', 'model', 'note', 'that', 'transformerbigsinglegpu', 'tran', 'formerbasesinglegpu', 'just', 'name', 'set', 'hyperparamet', 'which', 'appli', 'even', 'when', 'train', 'multipl', 'gpu', 'our', 'experi', 'see', 'section', '47', 'onesuperior', 'our', 'baselineset', 'use', 'thebig', 'model', 'withit', 'default', 'hyperparametersexcept', 'batchsiz', 'see', 'discuss', 'di', 'erent', 'size', 'section', '45', 'trainstep', 'ie', 'highenough', 'sowecanstopeachexperimentman', 'ualli', 'need', 'savecheckpointssec', 'which', 'forc', 'checkpoint', 'save', 'each', 'hour', 'see', 'section', '410', 'scheduletrain', 'which', 'disabl', 'intern', 'evalu', 'with', 'approxbleu', 'thu', 'make', 'train', 'bit', 'faster', 'see', 'section', '2', 'onesuperior', '41', 'comput', 'speed', 'train', 'throughput', 'primarili', 'interest', 'translat', 'qualiti', 'bleu', 'learn', 'curv', 'timetillscor', 'andwediscussitinthefollowingsect', 'inthissect', 'focushoweveronlyonth', 'computationspe', 'andtrainingthroughput', 'botharea', 'ect', 'by', 'three', 'import', 'factor', 'batch', 'size', 'number', 'use', 'gpu', 'model', 'size', 'speed', 'usual', 'almost', 'constant', 'given', 'experi', 'onesuperior', 'tabl', '2', 'show', 'comput', 'speed', 'train', 'throughput', 'singl', 'gpu', 'variou', 'batch', 'size', 'model', 'size', 'base', 'big', 'base', 'model', 'allow', 'use', 'higher', 'batch', 'size', 'than', 'big', 'model', 'cell', 'where', 'big', 'model', 'result', 'outofmemori', 'error', 'mark', 'with', 'oom', 'onesuperiorw', 'see', 'that', 'onesuperioraccord', 'our', 'experi', 'not', 'report', 'here', 'transformerbigsinglegpu', 'better', 'than', 'tran', 'formerbig', 'even', 'when', 'train', '8', 'gpu', 'although', 'name', 'suggest', 'that', 'tt', 'author', 'an', 'opposit', 'experi', 'onesuperioralsotherearesomeproblemswiththealternativeschedul', 'trainandevalu', 'itneedsmoremem', 'ori', 'continuoustrainandev', 'see', 'http', 'githubcomtensorflowtensortensorissu', 'onesuperiortensorboard', 'show', 'globalstepsec', 'statist', 'ie', 'comput', 'speed', 'curv', 'these', 'curv', 'our', 'experimentsarealmostconstantforthewholetrainingwithvariationwithin', 'exceptformomentswhen', 'checkpoint', 'be', 'save', 'comput', 'speed', 'thu', 'much', 'slower', 'onesuperiorfor', 'these', 'experi', 'use', 'maxlength', 'order', 'abl', 'test', 'bigger', 'batch', 'size', 'howev', 'addit', 'experi', 'check', 'that', 'maxlength', 'doe', 'not', 'ect', 'train', 'throughput', 'itself', 'model', 'batchsiz', 'base', 'big', 'k', 'k', 'k', 'k', 'k', 'k', 'k', 'k', 'k', 'k', 'k', 'oom', '4500', 'k', 'oom', '6000', 'k', 'oom', 'comput', 'speed', 'stepshour', 'model', 'batchsiz', 'base', 'big', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'oom', 'm', 'oom', 'm', 'oom', 'b', 'train', 'throughput', 'subwordshour', 'tabl', '2', 'comput', 'speed', 'train', 'throughput', 'singl', 'gpu', 'comput', 'speed', 'decreas', 'with', 'increas', 'batch', 'size', 'becaus', 'not', 'oper', 'gpu', 'fulli', 'batchparalleliz', 'train', 'throughput', 'grow', 'sublinearli', 'with', 'increas', 'batch', 'size', 'so', 'base', 'these', 'experi', 'onli', 'there', 'just', 'small', 'advantag', 'when', 'set', 'batch', 'size', 'maximum', 'valu', 'will', 'return', 'thi', 'question', 'section', '45', 'while', 'take', 'into', 'account', 'translat', 'qualiti', 'also', 'see', 'base', 'model', 'approxim', 'two', 'time', 'bigger', 'throughput', 'well', 'comput', 'speed', 'rel', 'big', 'model', 'gpu', 'stepshour', 'subwordshour', '1', 'k', 'm', '2', 'k', 'm', '6', 'k', 'm', '8', 'k', 'm', 'tabl', '3', 'comput', 'speed', 'train', 'throughput', 'variou', 'number', 'gpu', 'with', 'big', 'model', 'batchsiz', 'tabl', '3', 'use', 'big', 'model', 'batchsiz', 'while', 'vari', 'number', 'gpu', 'overhead', 'gpu', 'synchron', 'appar', 'from', 'decreas', 'com', 'putat', 'speed', 'nevertheless', 'train', 'throughput', 'still', 'grow', 'with', 'more', 'gpu', 'so', 'eg', 'with', '6', 'gpu', 'process', '32', 'time', 'more', 'train', 'data', 'per', 'hour', 'rel', 'singl', 'gpu', 'while', 'without', 'ani', 'overhead', 'would', 'hypothet', 'expect', '6', 'time', 'more', 'data', '924252627', '0', '50', '100', '150', '200', 'bleu', 'train', 'time', 'hour', 'train', 'time', 'day', 'm', 'train', 'sentenc', 'm', 'train', 'sentenc', 'figur', '1', 'train', 'data', 'size', 'e', 'ect', 'bleu', 'learn', 'curv', 'our', 'main', 'train', 'dataset', 'with', '58', 'million', 'sentenc', 'pair', 'an', 'altern', 'train', 'dataset', 'with', '16', 'million', 'sentenc', 'pair', 'both', 'train', 'with', '8', 'gpu', 'big', 'model', 'batchsiz', 'overhead', 'when', 'scale', 'multipl', 'gpu', 'smaller', 'than', 'overhead', 'when', 'scale', 'higher', 'batch', 'size', 'scale', 'from', 'singl', 'gpu', '6', 'gpu', 'increas', 'throughput', '32', 'time', 'but', 'scale', 'from', 'batch', 'size', '1000', '6000', 'singl', 'gpu', 'increas', 'throughput', '13', 'time', '42', 'train', 'data', 'size', 'forthisexperi', 'wesubstitutedczengwithczenginthetrainingdata', 'sothetotaltrainingsizeismillionsentencepair', 'mmofenglishczech', 'word', 'figurecomparesthebleulearningcurvesoftwoexperimentswhichdi', 'er', 'onli', 'train', 'data', 'baselin', 'czeng', '17', 'versu', 'smaller', 'czeng', '10', 'both', 'train', 'same', 'hardwar', 'with', 'same', 'hyperparamet', '8', 'gpu', 'big', 'batchsiz', 'train', 'smaller', 'dataset', '25', 'time', 'smaller', 'number', 'word', 'converg', 'bleu', 'about', '255', 'after', 'two', 'day', 'train', 'doe', 'not', 'improv', 'over', 'next', 'week', 'train', 'train', 'bigger', 'dataset', 'give', 'slightli', 'wors', 'result', 'rst', 'eight', 'hour', 'train', 'not', 'shown', 'graph', 'but', 'clearli', 'better', 'result', 'after', 'two', 'day', 'train', 'reach', 'over', '265', 'bleu', 'after', 'eight', 'day', 'onesuperior', 'with', 'batchsiz', 'andgpu', 'trainingoneepochofthesmallerdataset', 'with', 'czeng', 'takeskstep', 'hoursoftrain', 'comparedtokstep', 'hour', 'bigger', 'dataset', 'with', 'czeng', '17', 'thi', 'mean', 'about', '10', 'epoch', 'smaller', 'dataset', 'were', 'need', 'reach', 'converg', 'thi', 'also', 'moment', 'when', 'bigger', 'onesuperiorw', 'compar', 'two', 'dataset', 'also', 'anoth', 'experi', 'with', 'two', 'gpu', 'where', 'czeng', '17', 'gave', 'slightli', 'wors', 'result', 'than', 'czeng', '10', 'dure', 'rst', 'two', 'day', 'train', 'but', 'clearli', 'better', 'result', 'after', 'eight', 'day', 'hypothes', 'czeng', '10', 'somewhat', 'cleaner', 'than', 'czeng', '17', 'datasetstartsbeingclearlybett', 'howev', 'evenepochsinthebiggerdatasetwerenot', 'enough', 'reach', 'converg', 'enough', 'reach', 'converg', 'tip', 'train', 'data', 'size', 'compar', 'di', 'erent', 'dataset', 'eg', 'smaller', 'cleaner', 'vs', 'bigger', 'noisier', 'need', 'train', 'long', 'enough', 'becaus', 'result', 'after', 'rst', 'hour', 'or', 'day', 'if', 'train', 'singl', 'gpu', 'may', 'mislead', 'larg', 'train', 'data', 'czeng', '17', 'which', 'over', 'half', 'gigaword', 'bleu', 'improv', 'even', 'after', 'one', 'week', 'train', 'eight', 'gpu', 'or', 'after', '20', 'day', 'train', 'two', 'gpu', 'anoth', 'experi', 'not', 'easili', 'interpol', 'one', 'dataset', 'result', 'anoth', 'dataset', 'while', 'smaller', 'train', 'data', 'with', 'czeng', '10', 'converg', 'after', '2', 'day', 'main', 'train', 'data', 'with', 'czeng', '17', 'which', '25', 'time', 'bigger', 'continu', 'improv', 'even', 'after', '252', 'day', 'onesuperior', '43', 'model', 'size', 'choos', 'right', 'model', 'size', 'import', 'practic', 'reason', 'larger', 'model', 'maynot', 'tanymoreonyourgpuortheymayrequiretouseaverysmallbatchs', 'experi', 'with', 'two', 'model', 'twosuperiora', 'prede', 'ned', 'tensortensor', 'transfor', 'merbigsinglegpu', 'big', 'transformerbasesinglegpu', 'base', 'which', 'di', 'er', 'four', 'hyperparamet', 'summar', 'tabl', '4', 'model', 'hiddens', 'ltersiz', 'numhead', 'adambeta', 'base', '512', '2048', '8', '0980', 'big', '1024', '4096', '16', '0998', 'tabl', 'transformerbigsinglegpu', 'big', 'transformerbasesinglegpu', 'base', 'hyperparamet', 'di', 'erenc', 'figureshowsthatonasinglegpu', 'thebigmodelbecomesclearlybetterthanth', 'basemodelafterhoursoftrainingifwekeepthebatchsizethesam', 'andw', 'con', 'rmed', 'it', 'with', '1500', 'other', 'experi', 'howev', 'base', 'model', 'take', 'lessmemori', 'sowecana', 'ordahigherbatchs', 'inourcas', 'withno', 'maxlength', 'restrict', 'seethenextsect', 'whichimprovesthebleu', 'seesect', 'buteven', 'onesuperior', 'althoughsuchanexpectationmayseemnav', 'wecan', 'nditinliteratur', 'forexampl', 'bottou', '2012', 'insectionwrit', 'expectthevalidationperformancetoplateauafteranumberofepochsroughlycomparableto', 'number', 'epoch', 'need', 'reach', 'thi', 'point', 'small', 'train', 'set', 'twosuperiorw', 'tri', 'also', 'model', 'three', 'time', 'larg', 'base', '15', 'time', 'larg', 'big', 'but', 'it', 'did', 'not', 'reach', 'better', 'result', 'than', 'big', 'so', 'don', 't', 'report', 'it', 'here', '111618202224', '0', '10', '20', '30', '40', '50', '60', 'bleu', 'train', 'time', 'hour', 'big', 'model', 'batch', 'size', '2000', '1', 'gpu', 'base', 'model', 'batch', 'size', '4500', '1', 'gpu', 'base', 'model', 'batch', 'size', '2000', '1', 'gpu', 'figur', '2', 'e', 'ect', 'model', 'size', 'batch', 'size', 'singl', 'gpu', '2223242526', '0', '10', '20', '30', '40', 'bleu', 'train', 'time', 'hour', 'big', 'model', 'batch', 'size', '1500', '8', 'gpu', 'base', 'model', 'batch', 'size', '4500', '8', 'gpu', 'figur', '3', 'e', 'ect', 'model', 'size', 'batch', 'size', '8', 'gpu', 'so', 'after', 'less', 'than', 'one', 'day', 'train', 'big', 'with', 'batch', 'size', '2000', 'becom', 'better', 'than', 'base', 'with', 'batch', 'size', '4500', 'or', 'even', '6000', 'with', 'maxlength', '70', 'anoth', 'experi', 'di', 'erenc', 'grow', '18', 'bleu', 'after', 'three', 'day', 'train', 'figurecon', 'rmsthiswithgpusherebigwithbatchsizebecomesclearli', 'better', 'than', 'base', 'with', 'batch', 'size', '4500', 'after', '18', 'hour', 'train', 'tip', 'model', 'size', 'prefer', 'big', 'over', 'base', 'model', 'if', 'you', 'plan', 'train', 'longer', 'than', 'one', 'day', '11', 'gb', 'or', 'more', 'memori', 'avail', 'gpu', 'with', 'less', 'memori', 'you', 'should', 'benchmark', 'big', 'base', 'with', 'maximum', 'possibl', 'batch', 'size', 'maximum', 'batch', 'size', 'longer', 'sentenc', 'maxlength', 'bigadam', 'bigadafactor', 'baseadam', 'train', 'test', 'none', '2040', '2550', '4950', '00', '00', '150', '2230', '2970', '5430', '02', '00', '100', '2390', '3280', '5990', '07', '03', '702630', '3590', '6290', '21', '22', '502750', '3770', '6430', '50', '91', 'tabl', 'maximumbatchsizewhich', 'tsintogbmemoryforvariouscombin', 'ofmaxlength', 'maximum', 'sentenc', 'length', 'subword', 'model', 'size', 'base', 'or', 'big', 'optim', 'adam', 'or', 'adafactor', 'last', 'two', 'column', 'show', 'percentag', 'sentenc', 'train', 'czeng', '17', 'test', 'wmt', 'data', 'that', 'longer', 'than', 'given', 'threshold', 'forfastdebug', 'ofmodelsizeunrelatedaspect', 'useamodelcal', 'tran', 'formertini', '44', 'maximum', 'train', 'sentenc', 'length', 'theparamet', 'maxlength', 'speci', 'esthemaximumlengthofasentenceinsubword', 'longersent', 'eitherinsourceortargetlanguag', 'areexcludedfromthetrain', 'complet', 'if', 'maxlength', 'speci', 'ed', 'which', 'default', 'batchsiz', 'use', 'instead', 'loweringth', 'maxlength', 'allowstouseahigherbatchsizeorabiggermodel', 'sinc', 'transform', 'implement', 'tt', 'suddenli', 'run', 'out', 'memori', 'even', 'after', 'sever', 'hour', 'train', 'it', 'good', 'know', 'how', 'larg', 'batch', 'size', 'ts', 'your', 'gpu', 'tabl', '5', 'present', 'what', 'empir', 'measur', 'base', 'big', 'model', 'with', 'adam', 'adafactor', 'twosuperioronesuperioroptim', 'variou', 'maxlength', 'valu', 'set', 'maxlength', 'toolowwouldresultinexcludingtoomanytrainingsent', 'bias', 'translat', 'toward', 'shorter', 'sentenc', 'which', 'would', 'hurt', 'tran', 'lation', 'qualiti', 'last', 'two', 'column', 'tabl', '5', 'show', 'that', 'set', 'maxlength', '70', 'resp', '100', 'result', 'exclud', 'onli', '21', 'resp', '07', 'sentenc', 'train', 'data', 'onli', '22', 'resp', '03', 'sentenc', 'develop', 'test', 'data', 'longer', 'so', 'detriment', 'e', 'ect', 'smaller', 'train', 'data', 'length', 'bia', 'should', 'minim', 'thi', 'set', 'howev', 'our', 'experi', 'with', 'batchsiz', '1500', 'figur', '4', 'show', 'strang', 'drop', 'bleu', 'after', 'one', 'hour', 'train', 'experi', 'with', 'maxlength', '70', 'or', 'lower', 'even', 'with', 'maxlength', '150', 'or', '200', 'bleu', 'learn', 'curv', 'wors', 'than', 'with', 'maxlength', '400', 'which', 'nallygivesthesameresultasnotusingani', 'maxlength', 'twosuperioronesuperiortheadafactoroptim', 'shazeerandstern', 'isavailableonlyinttornewerandhasthre', 'time', 'smaller', 'model', 'than', 'adam', 'becaus', 'it', 'doe', 'not', 'store', 'rst', 'second', 'moment', 'weight', 'leav', 'further', 'experi', 'with', 'adafactor', 'futur', 'work', '13051015', 'bleu', 'train', 'time', 'hour', 'max', 'length', '400', 'max', 'length', '200', 'max', 'length', '150', 'max', 'length', '70', 'max', 'length', '50', 'max', 'length', '25', 'figur', '4', 'e', 'ect', 'restrict', 'train', 'data', 'variou', 'maxlength', 'valu', 'train', 'singl', 'gpu', 'with', 'big', 'model', 'batchsiz', '1500', 'an', 'experi', 'without', 'ani', 'maxlength', 'not', 'shown', 'but', 'it', 'same', 'curv', 'maxlength', '400', 'restrict', 'thetraininglossof', 'maxlength', '25', 'andand', 'hashighvarianceand', 'stop', 'improv', 'after', 'rst', 'hour', 'train', 'but', 'show', 'sudden', 'increas', 'case', 'diverg', 'train', 'discuss', 'section', '46', 'when', 'learn', 'rate', 'too', 'high', 'explan', 'thi', 'phenomenon', 'twosuperiortwosuperior', 'did', 'anoth', 'set', 'experi', 'with', 'vari', 'maxlength', 'but', 'thi', 'time', 'with', 'batchsiz', '2000', 'instead', '1500', 'thi', 'case', 'maxlength', '25', '50', 'still', 'result', 'slowergrowingbleucurv', 'butandhigherhasthesamecurveasno', 'maxlength', 'restrict', 'so', 'our', 'case', 'if', 'batch', 'size', 'high', 'enough', 'maxlength', 'almost', 'e', 'ect', 'bleu', 'but', 'thi', 'should', 'check', 'each', 'new', 'dataset', 'train', 'sever', 'model', 'with', 'variou', 'maxlength', 'three', 'day', 'observ', 'thattheyarenotabletoproducelongertranslationsthanwhatwasthemaximumlengthus', 'train', 'even', 'if', 'chang', 'decod', 'paramet', 'alpha', 'tip', 'maxlength', 'set', 'reason', 'low', 'maxlength', 'thi', 'allow', 'use', 'higher', 'batch', 'size', 'prevent', 'outofmemori', 'error', 'after', 'sever', 'hour', 'train', 'also', 'with', 'higher', 'percentag', 'train', 'sentenc', 'that', 'almost', 'maxlength', 'long', 'there', 'isahigherchancethatthetrainingwillfaileitherimmedi', 'ifthebatchs', 'too', 'high', 'or', 'never', 'otherwis', 'setareasonablyhigh', 'maxlength', 'considerthepercentageofsentencesexclud', 'fromtrainingandfromthetargeteddevelopmenttestsetandalsowatchforun', 'expecteddrop', 'orstagn', 'ofthebleucurveinth', 'rsthoursoftrain', 'twosuperiortwosuperiorhttp', 'githubcomtensorflowtensortensorissu', '1410121416182022', '0', '10', '20', '30', '40', '50', '60', 'bleu', 'train', 'time', 'hour', 'base', 'batch', 'size', '6000', 'base', 'batch', 'size', '4500', 'base', 'batch', 'size', '3000', 'base', 'batch', 'size', '1500', 'base', 'batch', 'size', '1000', 'figur', '5', 'e', 'ect', 'batch', 'size', 'with', 'base', 'model', 'train', 'singl', 'gpu', '45', 'batch', 'size', 'thedefault', 'batchsiz', 'valueinrecentttversionsissubwordsforallmodel', 'except', 'transformerbasesinglegpu', 'where', 'default', '2048', 'howev', 'recommend', 'alway', 'set', 'batch', 'size', 'explicitli', 'twosuperiorthreesuperioror', 'least', 'make', 'note', 'what', 'wa', 'default', 'given', 'tt', 'version', 'when', 'report', 'experiment', 'result', 'figureshowslearningcurvesfor', 'vedi', 'erentbatchs', '1000150030004500', '6000', 'experi', 'with', 'singl', 'gpu', 'base', 'model', 'twosuperiora', 'higher', 'batch', 'sizeup', '4500', 'clearli', 'better', 'term', 'bleu', 'measur', 'by', 'time', 'till', 'score', 'examplestillscoremetricsd', 'nedinsect', 'forexampl', 'togetoverbleuof', 'with', 'batchsiz', '3000', 'weneedhour', 'mexampl', 'andwith', 'batchsiz', '1500', 'need', 'about', '3', 'day', 'm', 'exampl', 'ie', '10', 'time', 'longer', '9', 'time', 'more', 'exampl', 'fromtableaweknowthatbiggerbatcheshaveslowercomputationspe', 'sowhen', 'replot', 'figur', '5', 'with', 'step', 'instead', 'time', 'xaxi', 'di', 'erenc', 'between', 'curv', 'would', 'even', 'bigger', 'from', 'tabl', 'b', 'know', 'that', 'bigger', 'batch', 'slightli', 'higher', 'train', 'throughput', 'so', 'when', 'replot', 'with', 'number', 'exampl', 'process', 'xaxi', 'di', 'erenc', 'will', 'smaller', 'but', 'still', 'visibl', 'onli', 'exceptionisthedi', 'erencebetweenbatchsizeand', 'whichisverysmalland', 'twosuperiorthreesuperioreg', 'hparam', 'batchsiz', 'learningr', 'learningratewarmupstep', 'batch', 'size', 'speci', 'ed', 'subword', 'see', 'advantag', 'use', 'poweroftwo', 'valu', 'twosuperioral', 'experi', 'figur', '5', 'use', 'maxlength', '70', 'but', 'got', 'same', 'curv', 'when', 'rerun', 'without', 'ani', 'maxlength', 'restrict', 'except', 'batchsiz', '6000', 'which', 'fail', 'with', 'oom', '1505101520', '0', '5', '10', '15', '20', '25', '30', 'bleu', 'train', 'time', 'hour', 'big', 'batch', 'size', '2000', 'big', 'batch', 'size', '1500', 'big', 'batch', 'size', '1450', 'big', 'batch', 'size', '1400', 'big', 'batch', 'size', '1300', 'big', 'batch', 'size', '1000', 'figur', '6', 'e', 'ect', 'batch', 'size', 'with', 'big', 'model', 'train', 'singl', 'gpu', 'canbefullyexplainedbythefactthatbatchsizeha', 'higherthroughputthan', 'batch', 'size', '4500', 'sofor', 'base', 'model', 'higher', 'batch', 'size', 'give', 'better', 'result', 'although', 'with', 'dimin', 'ish', 'return', 'thi', 'observ', 'goe', 'against', 'common', 'knowledg', 'other', 'nmt', 'framework', 'deep', 'learn', 'gener', 'keskar', 'et', 'al', '2017', 'that', 'smaller', 'batch', 'proceedslow', 'trainingexamplesperhour', 'butresultinbettergener', 'higher', 'testset', 'bleu', 'end', 'our', 'experi', 'with', 'base', 'model', 'tt', 'bigger', 'batch', 'not', 'onli', 'faster', 'train', 'throughput', 'could', 'expect', 'but', 'also', 'faster', 'converg', 'speed', 'time', 'till', 'score', 'exampl', 'till', 'score', 'interestingli', 'when', 'replic', 'these', 'experi', 'with', 'big', 'model', 'see', 'quit', 'di', 'erentresult', 'asshowninfigur', 'thebigmodelneedsacertainminimalbatchs', 'tostartconvergingatal', 'butforhigherbatchsizesthereisalmostnodi', 'erenceinth', 'bleucurv', 'butstil', 'biggerbatchnevermakesthebleuworseinourexperi', 'our', 'case', 'sharp', 'di', 'erenc', 'between', 'batch', 'size', '1450', 'which', 'train', 'well', '1400', 'which', 'drop', 'o', 'after', 'two', 'hour', 'train', 'recov', 'onli', 'slowli', 'accord', 'smith', 'le', '2017', 'smith', 'et', 'al', '2017', 'gradient', 'nois', 'scale', 'ie', 'scaleofrandom', 'uctuationsinthesgd', 'oradametc', 'dynam', 'isproport', 'learn', 'rate', 'divid', 'by', 'batch', 'size', 'cf', 'section', '48', 'thu', 'when', 'lower', 'batchsiz', 'weincreasethenoisescaleandthetrainingmay', 'diverg', 'thismaybeeith', 'perman', 'case', 'batch', 'size', '1000', 'figur', '6', 'or', 'temporari', 'case', 'batch', 'size', '1300', '1400', 'where', 'bleu', 'continu', 'grow', 'after', 'temporari', 'drop', 'but', 'much', 'more', 'slowli', 'than', 'nondiverg', 'curv', 'not', 'sure', 'what', 'caus', 'di', 'erenc', 'between', 'base', 'big', 'model', 'with', 'regard', 'sensit', 'batch', 'size', 'one', 'hypothesi', 'that', 'big', 'model', '1605101520', 'bleu', 'train', 'time', 'hour', 'learn', 'rate', '025', 'learn', 'rate', '020', 'learn', 'rate', '010', 'learn', 'rate', '005', 'learn', 'rate', '001', 'figur', '7', 'e', 'ect', 'learn', 'rate', 'singl', 'gpu', 'train', 'czeng', '10', 'with', 'default', 'batch', 'size', '1500', 'warmup', 'step', 'k', 'more', 'di', 'cult', 'initi', 'thu', 'more', 'sensit', 'diverg', 'earli', 'train', 'phase', 'also', 'while', 'base', 'increas', 'batch', 'size', 'wa', 'highli', 'help', 'until', '4500', 'big', 'thi', 'limit', 'may', 'below', '1450', 'ie', 'below', 'minim', 'batch', 'size', 'need', 'prevent', 'diverg', 'train', 'tip', 'batch', 'size', 'batch', 'size', 'should', 'set', 'high', 'possibl', 'while', 'keep', 'reserv', 'not', 'hit', 'outofmemori', 'error', 'it', 'advis', 'establish', 'largest', 'possibl', 'batch', 'size', 'befor', 'start', 'main', 'long', 'train', '46', 'learn', 'rate', 'warmup', 'step', 'singl', 'gpu', 'default', 'learn', 'rate', 'tt', 'translat', 'model', '020', 'figur', '7', 'show', 'that', 'vari', 'valu', 'within', 'rang', '005025', 'make', 'almost', 'di', 'erenc', 'set', 'learningratetoolow', '001', 'resultsinnotablyslowerconverg', 'settingthelearn', 'rate', 'too', 'high', '030', 'not', 'shown', 'gure', 'result', 'divergedtrain', 'which', 'mean', 'inthiscasethatthelearningcurvestartsgrowingasusu', 'butatonemomentdrop', 'down', 'almost', 'zero', 'stay', 'there', 'forev', 'common', 'solut', 'prevent', 'diverg', 'train', 'decreas', 'learningr', 'paramet', 'or', 'increas', 'learningratewarmupstep', 'or', 'introduc', 'gradient', 'clip', 'learningratewarmupstep', 'paramet', 'con', 'gure', 'linearwarmuprsqrtdecay', 'schedul', 'twosuperiorand', 'it', 'set', '16', '000', 'by', 'default', 'big', 'model', 'mean', 'that', 'within', 'twosuperiorth', 'schedul', 'wa', 'call', 'noamin', 'tt', 'version', 'older', 'than', '144', '1705101520', 'bleu', 'train', 'time', 'hour', 'warmup', 'step', 'k', 'warmup', 'step', 'k', 'warmup', 'step', 'k', 'warmup', 'step', 'k', 'warmup', 'step', 'k', 'figur', '8', 'e', 'ect', 'warmup', 'step', 'singl', 'gpu', 'train', 'czeng', '10', 'with', 'default', 'batch', 'size', '1500', 'learn', 'rate', '020', 'rstkstepsthelearningrategrowslinearlyandthenfollowsaninversesquar', 'root', 'decay', 't', 'cf', 'section', '483', 'k', 'step', 'actual', 'learn', 'rate', 'thu', 'highest', 'if', 'diverg', 'happen', 'it', 'usual', 'happen', 'within', 'rst', 'few', 'hour', 'train', 'when', 'actual', 'learn', 'rate', 'becom', 'highest', 'increas', 'warmup', 'step', 'from', 'k', 'k', 'were', 'abl', 'train', 'with', 'learn', 'rate', '030', 'even', '050', 'without', 'ani', 'diverg', 'learn', 'curv', 'look', 'similarli', 'baselineon', 'withdefaultvaluesofkwarmupstepsandlearningr', 'when', 'tryinglearningr', 'wehadtoincreasewarmupstepstok', 'withkthetrain', 'divergedafteronehour', 'thisresultedinaslowerconvergenceat', 'rst', 'aboutbleu', 'lowerthanthebaselineafterhoursoftrain', 'butafterdaysoftraininghav', 'same', 'curv', 'baselin', 'figureshowsthe', 'ectofdi', 'erentwarmupstepswitha', 'xedlearningr', 'default', 'settingwarmupstepstoolow', 'k', 'resultsindivergedtrain', 'set', 'them', 'too', 'high', 'k', 'green', 'curv', 'result', 'slightli', 'slower', 'converg', 'rst', 'but', 'match', 'baselin', 'after', 'few', 'hour', 'train', 'conclud', 'that', 'singl', 'gpu', 'big', 'model', 'there', 'rel', 'largerangeoflearningrateandwarmupstepsvaluesthatachievetheoptimalresult', 'default', 'valu', 'learningr', '020', 'learningratewarmupstep', '16000', 'within', 'thi', 'rang', 'tip', 'learn', 'rate', 'warmup', 'step', 'case', 'diverg', 'train', 'tri', 'gradient', 'clip', 'andor', 'more', 'warmup', 'step', 'ifthatdoesnothelp', 'orifthewarmupstepsaretoohighrelativetotheexpect', 'total', 'train', 'step', 'tri', 'decreas', 'learn', 'rate', 'note', 'that', 'when', 'you', 'decreas', 'warmup', 'step', 'keep', 'learn', 'rate', 'you', 'also', 'increas', 'maximum', 'actual', 'learn', 'rate', 'becaus', 'way', 'how', 'lin', 'earwarmuprsqrtdecay', 'aka', 'noam', 'schedul', 'implement', 'twosuperior', '47', 'number', 'gpu', 'tt', 'allow', 'train', 'with', 'multipl', 'gpu', 'same', 'machin', 'simpli', 'use', 'paramet', 'workergpu', 'twosuperiora', 'explain', 'section', '23', 'paramet', 'batchsiz', 'interpret', 'per', 'gpu', 'so', 'with', '8', 'gpu', 'e', 'ectiv', 'batch', 'size', '8', 'time', 'bigger', 'asinglegpuexperimentwithbatchs', 'shouldgiveexactlythesameresult', 'two', 'gpu', 'batch', 'size', '2000', 'four', 'gpu', 'batch', 'size', '1000', 'becaus', 'e', 'ectiv', 'batch', 'size', '4000', 'three', 'case', 'con', 'rmed', 'thi', 'empir', 'by', 'same', 'result', 'mean', 'bleu', 'or', 'train', 'loss', 'versu', 'train', 'step', 'xaxi', 'whenconsideringtim', 'thefourgpuexperimentwillbethefasteston', 'asexplain', 'section', '41', 'figur', '9', 'show', 'bleu', 'curv', 'di', 'erent', 'number', 'gpu', 'big', 'model', 'with', 'batch', 'size', 'learn', 'rate', 'warmup', 'step', 'xed', 'their', 'default', 'valu', '1500', 'andk', 'respect', 'ascouldbeexpect', 'trainingwithmoregpusconverg', 'faster', 'whatisinterestingisthetimetillscor', 'tableliststheapproximatetrain', 'timeandnumberoftrainingexampl', 'inmillionsofsubword', 'neededto', 'surpass', 'ie', 'achiev', 'never', 'again', 'fall', 'below', 'bleu', '256', 'gpu', 'hour', 'subword', 'm', '1', '600', '9000', '2', '203', '23222', '4644', '6', '56', '4516', '2706', '8', '40', '3418', '2728', 'tabl', '6', 'time', 'train', 'data', 'consum', 'reach', 'bleu', '256', 'ie', 'time', 'till', 'score', 'andexamplestillscor', 'notethattheexperimentongpuwasendedafterday', 'train', 'without', 'clearli', 'surpass', 'threshold', 'alreadi', 'outsid', 'figur', '9', 'twosuperiorthi', 'hold', 'least', 'tt', 'version', '129152', 'but', 'it', 'somewhat', 'unexpectedunintuit', 'some', 'user', 'it', 'may', 'xed', 'futur', 'see', 'http', 'githubcomtensorflowtensortensorissu', 'twosuperiorand', 'make', 'sure', 'environ', 'variabl', 'cudavisibledevic', 'set', 'so', 'enough', 'card', 'visibl', 'tt', 'allow', 'also', 'distribut', 'train', 'multipl', 'machin', 'but', 'not', 'experi', 'with', 'it', 'both', 'singlemachin', 'multigpu', 'distribut', 'train', 'use', 'synchron', 'adam', 'updat', 'by', 'default', '1923524245252552626527', '0', '50', '100', '150', '200', '250', '300', 'bleu', 'train', 'time', 'hour', 'train', 'time', 'day', 'gpu', 'gpu', 'gpu', 'gpu', '256', 'figur', '9', 'e', 'ect', 'number', 'gpu', 'bleu', 'mark', 'with', 'black', 'line', 'see', 'that', 'two', 'gpu', 'more', 'than', 'three', 'time', 'faster', 'than', 'singl', 'gpu', 'when', 'measur', 'time', 'till', 'score', 'need', 'much', 'less', 'train', 'exampl', 'ie', 'they', 'lowerexamplestillscor', 'similarli', 'eightgpusaremorethan', 'vetimesfasterthantwo', 'gpusand', '17', 'time', 'less', 'train', 'data', 'need', 'recal', 'that', 'figur', '6', 'shown', 'that', 'increas', 'batch', 'size', 'from', '1450', 'hasalmostno', 'ectonthebleucurv', 'howev', 'whenincreasingthe', 'ectiv', 'batch', 'size', 'by', 'use', 'more', 'gpu', 'improv', 'higher', 'than', 'could', 'expect', 'from', 'higher', 'throughput', 'twosuperiorw', 'nd', 'thi', 'quit', 'surpris', 'especi', 'consid', 'fact', 'that', 'not', 'tune', 'learn', 'rate', 'warmup', 'step', 'see', 'next', 'section', 'tip', 'number', 'gpu', 'fastest', 'bleu', 'converg', 'use', 'mani', 'gpu', 'avail', 'our', 'experi', 'ment', '8', 'thi', 'hold', 'even', 'when', 'there', 'more', 'experi', 'done', 'exampl', 'it', 'better', 'run', 'one', 'gpu', 'experi', 'after', 'anoth', 'rather', 'than', 'run', 'two', 'gpu', 'experi', 'parallel', 'or', 'eight', 'singlegpu', 'experi', 'parallel', 'twosuperiorit', 'would', 'interest', 'tri', 'simul', 'multigpu', 'train', 'singl', 'gpu', 'simpli', 'by', 'do', 'updateonceafternbatch', 'andsummingthegradi', 'thisissimilartoth', 'ghostbatch', 'ofho', 'eret', '2017', 'but', 'use', 'ghost', 'batch', 'size', 'higher', 'than', 'actual', 'batch', 'size', 'leav', 'thi', 'futur', 'work', '2048', 'learn', 'rate', 'warmup', 'step', 'multipl', 'gpu', '481', 'relat', 'work', 'thereisagrowingnumberofpapersonscalingdeeplearningtomultiplemachin', 'withsynchronoussgd', 'oritsvari', 'byincreasingthe', 'ectivebatchs', 'wewil', 'focu', 'mostli', 'question', 'how', 'adapt', 'learn', 'rate', 'schedul', 'when', 'scale', 'from', 'one', 'gpu', 'or', 'ani', 'devic', 'gener', 'kgpu', 'krizhevski', '2014', 'say', 'theori', 'suggest', 'that', 'when', 'multipli', 'batch', 'size', 'by', 'k', 'one', 'should', 'multipli', 'learn', 'rate', 'byv', 'kto', 'keep', 'varianc', 'gradient', 'expect', 'constant', 'without', 'actual', 'explain', 'which', 'theori', 'suggest', 'so', 'howev', 'experimentalparthereportsthatwhatworkedthebest', 'wasa', 'linearscalingheurist', 'ie', 'multipli', 'learn', 'rate', 'by', 'k', 'again', 'without', 'ani', 'explan', 'nor', 'detail', 'di', 'erenc', 'betweenv', 'kscale', 'kscale', 'linear', 'scale', 'heurist', 'becom', 'popular', 'lead', 'good', 'scale', 'result', 'practic', 'goyalet', 'smithet', 'andalsotheoreticalexplan', 'bottou', 'etal', 'smithandl', 'jastrzebskiet', 'smithandl', '2017', 'interpret', 'sgd', 'anditsvari', 'asastochasticdi', 'erentialequationandshowthatth', 'gradient', 'nois', 'scale', 'gequalx', 'n', 'b', 'where', 'learn', 'rate', 'ni', 'train', 'set', 'size', 'bi', 'e', 'ectiv', 'batch', 'size', 'thi', 'nois', 'drive', 'sgd', 'away', 'from', 'sharp', 'minima', 'therefor', 'there', 'an', 'optim', 'batch', 'size', 'which', 'maxim', 'test', 'set', 'accuraci', 'other', 'word', 'keep', 'optim', 'level', 'gradient', 'nois', 'which', 'lead', 'minima', 'that', 'gener', 'well', 'need', 'scale', 'learn', 'rate', 'linearli', 'when', 'increas', 'e', 'ectiv', 'batch', 'size', 'howev', 'ho', 'eret', '2017', 'suggesttousev', 'kscalinginsteadofthelinearsc', 'provid', 'both', 'theoret', 'empir', 'support', 'thi', 'claim', 'they', 'show', 'that', 'cov', 'w', 'w', '2', 'nb', 'thusifwewanttokeepthethecovariancematrixoftheparamet', 'updat', 'step', 'win', 'same', 'rang', 'ani', 'e', 'ectiv', 'batch', 'size', 'b', 'need', 'scale', 'learningrateproportionallytothesquarerootof', 'b', 'theyfoundthatv', 'kscalingwork', 'better', 'than', 'linear', 'scale', 'cifar', 'twosuperior', 'you', 'et', 'al', '2017', 'con', 'rm', 'linear', 'scale', 'doe', 'not', 'perform', 'well', 'imagenet', 'suggest', 'use', 'layerwis', 'adapt', 'rate', 'scale', 'wecanseethatlargebatchtrainingisstillanopenresearchquest', 'mostofth', 'paperscitedabovehaveexperimentalsupportonlyfromtheimagerecognitiontask', 'usuallyimagenet', 'andconvolutionalnetwork', 'eg', 'resnet', 'soitisnotclearwheth', 'their', 'suggest', 'appli', 'also', 'sequencetosequ', 'task', 'nmt', 'with', 'selfattent', 'network', 'transform', 'there', 'sever', 'other', 'di', 'erenc', 'well', 'modernconvolutionalnetworksareusuallytrainedwith', 'batchnorm', 'io', 'eand', 'szegedi', '2015', 'which', 'seem', 'import', 'scale', 'while', 'transform', 'use', 'twosuperior', 'toclosethegapbetweensmallbatchtrainingandlargebatchtrain', 'ho', 'eret', '2017', 'introduc', 'additiontov', 'kscale', 'socal', 'ghostbatchnorm', 'andadaptedtrainingregim', 'whichmeansdecay', 'learn', 'rate', 'after', 'given', 'number', 'step', 'instead', 'epoch', 'layer', 'normal', 'lei', 'ba', 'et', 'al', '2016', 'threesuperioralso', 'transform', 'use', 'adam', 'togeth', 'with', 'an', 'inversesquareroot', 'learningr', 'decay', 'while', 'most', 'imagenet', 'paper', 'use', 'sgd', 'with', 'momentum', 'piecewiseconst', 'learningr', 'decay', '482', 'our', 'experi', 'decid', 'nd', 'out', 'empir', 'optim', 'learn', 'rate', 'train', '8', 'gpu', 'increas', 'learn', 'rate', 'from', '020', '030', 'result', 'diverg', 'train', 'bleu', 'drop', 'almost', '0', 'after', 'two', 'hour', 'train', 'similarli', 'our', 'singlegpu', 'experi', 'section', '46', 'were', 'abl', 'prevent', 'diverg', 'by', 'increas', 'warmupstepsorbyintroducinggradientclip', 'eg', 'with', 'clipgradnorm', 'were', 'abl', 'use', 'learn', 'rate', '040', 'but', 'increas', 'it', 'further', '060', 'led', 'diverg', 'anyway', 'howev', 'none', 'these', 'experi', 'led', 'ani', 'improv', 'over', 'default', 'learn', 'rate', 'about', 'same', 'bleu', 'curv', 'after', 'few', 'hour', 'train', 'jastrzebski', 'et', 'al', '2017', 'show', 'that', 'invari', 'under', 'simultan', 'rescal', 'learn', 'rate', 'batch', 'size', 'break', 'down', 'if', 'learn', 'rate', 'get', 'too', 'larg', 'or', 'batch', 'size', 'get', 'too', 'small', 'similar', 'observ', 'wa', 'report', 'eg', 'by', 'bottou', 'et', 'al', '2016', 'thu', 'our', 'initi', 'hypothesi', 'wa', 'that', '020', 'or', '025', 'maxim', 'learn', 'rate', 'suitabl', 'stabl', 'train', 'our', 'experi', 'even', 'when', 'scale', 'from', 'singl', 'gputo', '8', 'gpu', 'consideringthisinitialhypothesi', 'weweresurprisedthatwewereabletoachieveso', 'goodtimetillscorewithgpu', 'morethantimessmallerrelativetoasinglegpu', 'report', 'tabl', '6', 'answer', 'thi', 'riddl', 'need', 'understand', 'how', 'learn', 'rate', 'schedul', 'implement', 'tt', '483', 'parametr', 'learn', 'rate', 'schedul', 'tt', 'most', 'work', 'learn', 'rate', 'schedul', 'threesuperioronesuperiorth', 'time', 'paramet', 'actual', 'inter', 'prete', 'number', 'epoch', 'or', 'train', 'exampl', 'exampl', 'popular', 'setup', 'forpiecewiseconstantdecayinimagenettrain', 'eggoyalet', 'istodivid', 'learn', 'rate', 'by', 'factor', '10', 'th', 'th', 'th', 'epoch', 'howev', 'intt', 'itisth', 'globalstep', 'variablethatisusedasth', 'time', 'paramet', 'so', 'when', 'increas', 'e', 'ectiv', 'batch', 'size', '8', 'time', 'eg', 'by', 'use', '8', 'gpu', 'instead', 'singlegpu', 'theactuallearningr', 'threesuperiortwosuperiorachievesagivenvalueafterthesamenumberof', 'step', 'butthismeansaftertimeslesstrainingexampl', 'fortheinversesquareroot', 'threesuperiorappli', 'batch', 'normal', 'rnn', 'di', 'cult', 'transform', 'doe', 'not', 'use', 'rnn', 'but', 'still', 'were', 'not', 'success', 'switch', 'batch', 'normal', 'possibl', 'ghost', 'batch', 'normal', 'due', 'nan', 'loss', 'error', 'threesuperioronesuperiorexamplesoflearningrateschedulesareinversesquarerootdecay', 'inversetimedecay', 'exponentiald', 'cay', 'piecewiseconst', 'decay', 'see', 'http', 'wwwtensorfloworgapiguidespythontrain', 'decayingth', 'learningr', 'tf', 'implement', 'threesuperiortwosuperiorbyactuallearningratewemeanthelearningrateafterapplyingthedecayschedul', 'learningr', 'paramet', 'stay', 'same', 'thi', 'case', 'decay', 'actuallr', 'step', 'equalxcstepsequalxv', 'actuallr', 'step', 'where', 'ci', 'constant', 'contain', 'also', 'learningr', 'paramet', 'so', 'with', '8', 'gpu', 'if', 'divid', 'thelearningr', 'paramet', 'byv', '8', 'achiev', 'same', 'actual', 'learn', 'rate', 'after', 'given', 'number', 'train', 'exampl', 'origin', 'singlegpu', 'set', 'thi', 'explain', 'riddl', 'from', 'previou', 'section', 'by', 'keep', 'learningr', 'paramet', 'same', 'when', 'scale', 'ktime', 'bigger', 'e', 'ectiv', 'batch', 'actual', 'increas', 'actuallearningratev', 'ktime', 'inaccordancewiththesuggestionofho', 'eret', '2017', 'threesuperiorthreesuperior', 'thi', 'hold', 'onli', 'linearwarmuprsqrtdecay', 'aka', 'noam', 'schedul', 'ignor', 'warmup', 'step', 'if', 'want', 'keep', 'same', 'learn', 'rate', 'also', 'warmup', 'phase', 'would', 'need', 'divid', 'warmup', 'step', 'by', 'k', 'howev', 'thi', 'mean', 'that', 'maximum', 'actual', 'learn', 'rate', 'will', 'bev', 'ktime', 'higher', 'rel', 'singlegpu', 'maxim', 'actual', 'learn', 'rate', 'thi', 'lead', 'diverg', 'our', 'experi', 'deed', 'mani', 'research', 'eg', 'goyal', 'et', 'al', '2017', 'suggest', 'use', 'warmup', 'when', 'scale', 'more', 'gpu', 'order', 'prevent', 'diverg', 'transform', 'use', 'learn', 'rate', 'warmup', 'by', 'default', 'even', 'singlegpu', 'train', 'cf', 'section', '46', 'but', 'it', 'make', 'sens', 'use', 'more', 'warmup', 'train', 'exampl', 'multigpu', 'set', 'our', 'experi', 'with', '8', 'gpu', 'default', 'learn', 'rate', '020', 'use', 'k', 'warmup', 'step', 'instead', 'default', 'k', 'e', 'ect', 'bleu', 'curv', 'it', 'wa', 'bit', 'higher', 'rst', 'few', 'hour', 'but', 'same', 'afterward', 'further', 'decreas', 'warmup', 'step', 'result', 'retard', 'bleu', 'curv', 'k', 'or', 'complet', 'diverg', 'k', 'tip', 'learn', 'rate', 'warmup', 'step', 'multipl', 'gpu', 'keep', 'learningr', 'paramet', 'it', 'optim', 'valu', 'found', 'singlegpu', 'experi', 'youcantrydecreasingthewarmupstep', 'butlessthanlinearlyandyoushould', 'not', 'expect', 'improv', 'nal', 'bleu', 'thi', 'way', '49', 'resum', 'train', 'ttallowstoresumetrainingfromacheckpoint', 'simplybypointingth', 'outputdir', 'parametertoadirectorywithanexistingcheckpoint', 'speci', 'edinth', 'checkpoint', 'le', 'thismaybeusefulwhenthetrainingfail', 'eg', 'becauseofhardwareerror', 'whenw', 'need', 'continu', 'train', 'di', 'erent', 'machin', 'or', 'dure', 'hyperparamet', 'search', 'when', 'want', 'continu', 'with', 'most', 'promis', 'setup', 'tt', 'save', 'also', 'adam', 'threesuperiorthreesuperiorin', 'addit', 'suggest', 'thev', 'klearningr', 'scale', 'ho', 'er', 'et', 'al', '2017', 'show', 'that', 'fulli', 'close', 'gener', 'gap', 'need', 'train', 'longer', 'becaus', 'absolut', 'number', 'step', 'updat', 'matter', 'so', 'from', 'thi', 'point', 'view', 'use', 'step', 'instead', 'epoch', 'time', 'paramet', 'learn', 'rate', 'schedul', 'may', 'not', 'complet', 'wrong', 'idea', '2326262264266268', '110', '120', '130', '140', '150', '160', '170', 'bleu', 'train', 'time', 'hour', 'averag', '16', 'checkpoint', 'averag', '8', 'checkpoint', 'averag', 'figur', '10', 'e', 'ect', 'checkpoint', 'averag', 'train', '6', 'gpu', 'momentumintothecheckpoint', 'sothetrainingcontinuesalmostasifithadnotbeen', 'stop', 'howev', 'itdoesnotstorethepositioninthetrainingdataitstartsfroma', 'randomposit', 'alsotherelativetim', 'andwallclocktim', 'intensorboardgraph', 'will', 'uenc', 'by', 'stop', 'resum', 'train', 'also', 'exploit', 'chang', 'some', 'hyperparamet', 'which', 'not', 'metaparametr', 'by', 'number', 'step', 'exampl', 'smith', 'etal', '2017', 'suggesttoincreasethe', 'ectivebatchs', 'andnumberofgpu', 'dure', 'train', 'instead', 'decay', 'learn', 'rate', 'yet', 'anoth', 'usag', 'domain', 'adapt', 'by', 'switch', 'from', 'larg', 'gener', 'domain', 'train', 'data', 'small', 'targetdomain', 'train', 'data', 'few', 'last', 'epoch', 'inthiscas', 'considereditingalsothelearningrateorlearningrateschedul', 'orfak', 'theglobalstep', 'store', 'checkpoint', 'make', 'sure', 'learn', 'rate', 'not', 'too', 'small', '410', 'checkpoint', 'averag', 'vaswaniet', '2017', 'suggesttoaveragethelastcheckpointssavedinminut', 'interv', 'use', 'utilsavgcheckpointspi', 'accord', 'our', 'experi', 'slightli', 'betterresultsareachievedwithaveragingcheckpointssavedinhourinterv', 'thi', 'also', 'advantag', 'that', 'less', 'time', 'spent', 'with', 'checkpoint', 'save', 'so', 'train', 'faster', 'figur', '10', 'show', 'e', 'ect', 'averag', 'twofold', 'averag', 'curv', 'lower', 'varianc', 'icker', 'from', 'checkpoint', 'checkpoint', 'it', 'almost', 'alway', 'better', 'than', 'baselin', 'without', 'averag', 'usual', 'by', 'about', '02', 'bleu', 'some', 'setup', 'seen', 'improv', 'due', 'averag', 'over', '1', 'bleu', 'earli', 'phase', 'train', 'while', 'baselin', 'learn', 'curv', 'grow', 'fast', 'it', 'better', 'use', 'fewer', 'manual', 'automat', 'score', 'ave', 'ave', 'z', 'bleu', 'ter', 'charact', 'beer', 'system', '238', '0662', '0582', '0543', 'tt', '8', 'gpu', '8', 'day', '1620', '0308', '228', '0667', '0588', '0540', 'uedinnmt', '2597', '0240', '201', '0703', '0612', '0519', 'onlineb', '3', '559', '0111', '202', '0696', '0607', '0524', 'limsifactor', '552', '0102', '200', '0699', 'liumfnmt', '552', '0090', '202', '0701', '0605', '0522', 'liumnmt', '541', '0050', '205', '0696', '0624', '0523', 'cuchimera', '533', '0029', '166', '0743', '0637', '0503', 'onlinea', '8', '419', '0327', '162', '0757', '0697', '0485', 'pjatk', 'tabl', 'wmtsystemsforenglishtoczechandourbesttttrainingrun', 'manual', 'score', 'from', 'o', 'cial', 'wmt', 'rank', 'automat', 'metric', 'were', 'provid', 'by', 'http', 'matrixstatmtorg', 'ter', 'metric', 'lower', 'better', 'best', 'result', 'bold', 'secondbest', 'ital', 'checkpoint', 'averag', 'later', 'phase', 'shown', 'figur', '10', 'after', '4575', 'day', 'train', 'it', 'seem', 'that', '16', 'checkpoint', 'cover', 'last', '16', 'hour', 'give', 'slightli', 'better', 'result', 'averag', 'than', '8', 'checkpoint', 'but', 'not', 'done', 'ani', 'proper', 'evalu', 'signi', 'canc', 'use', 'pair', 'bootstrap', 'test', 'each', 'hour', 'then', 'summar', 'result', 'fact', 'that', 'resum', 'train', 'start', 'from', 'random', 'posit', 'train', 'data', 'cf', 'section', '49', 'actual', 'exploit', 'fork', 'train', 'get', 'two', 'or', 'more', 'copi', 'model', 'which', 'train', 'same', 'number', 'step', 'but', 'independentlyinthelaterstagesandthusendingwithdi', 'erentweightssavedinth', 'nal', 'checkpoint', 'these', 'semiindepend', 'model', 'averag', 'same', 'way', 'ascheckpointsfromthesamerun', 'asdescribedabov', 'ourpreliminaryresultsshow', 'thi', 'help', 'bit', 'top', 'checkpoint', 'averag', 'tip', 'checkpoint', 'averag', 'use', 'it', 'averag', '8', 'checkpoint', 'take', 'about', '5', 'minut', 'so', 'it', 'bleu', 'boost', 'free', 'compar', 'with', 'time', 'need', 'whole', 'train', 'see', 'tool', 'automat', 'checkpoint', 'averag', 'evalu', 'describ', 'section', '24', '5', 'comparison', 'with', 'wmt', 'system', 'tabl', '7', 'provid', 'result', 'wmt', 'englishtoczech', 'news', 'translat', 'task', 'with', 'our', 'best', 'transform', 'model', 'big', 'train', '8', 'gpu', '8', 'day', 'averag', '8', 'checkpoint', 'evalu', 'use', 'exact', 'same', 'implement', 'automat', 'metric', 'while', 'automat', 'evalu', 'not', 'fulli', 'reliabl', 'see', 'eg', 'high', 'bleu', 'score', 'cuchimera', 'despit', 'it', 'lower', 'manual', 'rank', 'see', 'that', 'transform', 'model', 'outperform', 'best', 'system', 'bleu', 'ter', 'charact', 'beer', 'despit', 'it', 'doe', 'not', 'use', 'ani', 'backtransl', 'data', 'rerank', 'with', 'other', 'model', 'eg', 'righttoleft', 'rerank', 'norensembl', 'asisthecaseofuedinnmtandothersystem', 'notethat', 'our', 'transform', 'use', 'subset', 'constrain', 'train', 'data', 'wmt', 'so', 'result', 'compar', '6', 'conclus', 'present', 'broad', 'rang', 'basic', 'experi', 'with', 'transform', 'model', 'vaswani', 'et', 'al', '2017', 'englishtoczech', 'neural', 'machin', 'translat', 'while', 'limit', 'our', 'explor', 'more', 'or', 'less', 'basic', 'paramet', 'set', 'believ', 'thi', 'report', 'use', 'other', 'research', 'sum', 'experi', 'done', 'thi', 'articl', 'took', 'about', '4', 'year', 'gpu', 'time', 'among', 'other', 'practic', 'observ', 've', 'seen', 'that', 'transform', 'model', 'larger', 'batch', 'size', 'lead', 'not', 'onli', 'faster', 'train', 'but', 'more', 'importantli', 'better', 'tran', 'lation', 'qualiti', 'given', 'least', 'day', 'gb', 'gpu', 'train', 'larger', 'setup', 'big', 'shouldbealwayspref', 'thetransformermodelanditsimplementationin', 'tensortensor', 'also', 'best', 't', 'intens', 'train', 'use', 'mani', 'gpu', 'possibl', 'andrunningexperimentsoneafteranothershouldbepreferredoverrunningsever', 'singlegpu', 'experi', 'concurr', 'thebestperformingmodelweobtainedongpustrainedfordayshasoutp', 'form', 'wmt', 'winner', 'number', 'automat', 'metric', 'acknowledg', 'thi', 'research', 'wa', 'support', 'by', 'grant', 's', 'czech', 'scienc', 'foun', 'dation', 'hict', 'qt', 'oftheeu', 'svv', 'andusinglanguag', 'resourc', 'distribut', 'by', 'lindatclarin', 'project', 'ministri', 'educ', 'youth', 'sport', 'czech', 'republ', 'lm', 'bibliographi', 'bahdanau', 'dzmitri', 'kyunghyun', 'cho', 'yoshua', 'bengio', 'neural', 'machin', 'translat', 'by', 'jointli', 'learn', 'align', 'translat', 'proceed', 'iclr', '2015', 'bojar', 'ondrej', 'zdenek', 'abokrtsk', 'ondrej', 'duek', 'petra', 'galuckov', 'martin', 'majli', 'david', 'marecek', 'jir', 'mark', 'michal', 'novk', 'martin', 'popel', 'ale', 'tamchyna', 'joy', 'par', 'allel', 'with', 'czeng', '10', 'proceed', 'eighth', 'intern', 'languag', 'resourc', 'evaluationconfer', 'lrec', '12', 'page', 'istanbul', 'turkey', 'mayelra', 'euro', 'pean', 'languag', 'resourc', 'associ', 'isbn', '9782951740877', 'bojar', 'ondrej', 'ondrej', 'duek', 'tom', 'kocmi', 'jindrich', 'libovick', 'michal', 'novk', 'martin', 'popel', 'roman', 'sudarikov', 'duan', 'vari', 'czeng', '16', 'enlarg', 'czechenglish', 'parallel', 'corpu', 'with', 'process', 'tool', 'docker', 'sojka', 'petr', 'ale', 'hork', 'ivan', 'kopecek', 'karel', 'pala', 'editor', 'text', 'speech', 'dialogu', 'th', 'intern', 'confer', 'tsd', '2016', 'number', '9924', 'lectur', 'note', 'arti', 'cial', 'intellig', 'page', '231238', 'masaryk', 'univers', 'springer', 'intern', 'publish', '2016', 'isbn', '9783319455099', 'bojar', 'ondrej', 'rajenchatterje', 'christianfedermann', 'yvettegraham', 'barryhaddow', 'matthia', 'huck', 'philippkoehn', 'varvaralogacheva', 'christofmonz', 'matteonegri', 'mattpost', 'raphael', 'rubino', 'luciaspecia', 'andmarcoturchi', 'findingsoftheconferenceonmachinetran', 'lation', 'wmt', 'proceedingsofthesecondconferenceonmachinetransl', 'copenhagen', 'denmark', 'septemb', 'acl', 'bojar', 'ondrej', 'yvett', 'graham', 'amir', 'kamran', 'result', 'wmt', 'metric', 'share', 'task', 'proceed', 'second', 'confer', 'machin', 'translat', 'copenhagen', 'denmark', 'septemb', 'b', 'acl', 'bottou', 'lon', 'stochast', 'gradient', 'descent', 'trick', 'page', '421436', 'springer', 'berlin', 'heidelberg', 'berlin', 'heidelberg', '2012', 'isbn', '9783642352898', 'doi', '101007978364235289825', 'url', 'http', 'doiorg', 'bottou', 'l', 'f', 'e', 'curti', 'j', 'noced', 'optim', 'method', 'largescal', 'machin', 'learn', 'ingarxiv', 'eprint', 'june', '2016', 'url', 'http', 'arxivorgab', 'cettolo', 'mauro', 'marcello', 'federico', 'luisa', 'bentivogli', 'jan', 'niehu', 'sebastian', 'stker', 'katsuhito', 'sudoh', 'koichiro', 'yoshino', 'christian', 'federmann', 'overview', 'iwslt', '2017', 'evalua', 'tioncampaign', 'proceedingsofthethinternationalworkshoponspokenlanguagetransl', 'iwslt', 'page', '214', 'tokyo', 'japan', '2017', 'goyal', 'priya', 'piotrdollr', 'rossbgirshick', 'pieternoordhui', 'lukaszwesolowski', 'aapokyrola', 'andrewtulloch', 'yangqingjia', 'andkaimingh', 'accur', 'largeminibatchsgd', 'train', 'imagenet', '1', 'hour', 'corr', '2017', 'url', 'http', 'arxivorgab', 'ho', 'er', 'elad', 'itay', 'hubara', 'daniel', 'soudri', 'train', 'longer', 'gener', 'better', 'close', 'gener', 'gap', 'larg', 'batch', 'train', 'neural', 'network', 'guyon', 'i', 'u', 'v', 'luxburg', 's', 'bengio', 'h', 'wallach', 'r', 'fergu', 's', 'vishwanathan', 'r', 'garnett', 'editor', 'ad', 'vanc', 'neural', 'inform', 'process', 'system', '30', 'page', '17311741', 'curran', 'associ', 'inc', '2017', 'url', 'http', 'papersnipsccpapertrainlongergeneralizebetterclos', 'thegeneralizationgapinlargebatchtrainingofneuralnetworkspdf', 'io', 'e', 'sergeyandchristianszegedi', 'batchnorm', 'acceleratingdeepnetworktrain', 'byreducinginternalcovariateshift', 'corr', 'ab', 'url', 'http', 'arxivorg', 'ab', 'jastrzebski', 'stanislaw', 'zachari', 'kenton', 'devansh', 'arpit', 'nicola', 'balla', 'asja', 'fischer', 'yoshua', 'bengio', 'amo', 'j', 'storkey', 'three', 'factor', 'uenc', 'minima', 'sgd', 'corr', 'ab', '2017', 'url', 'http', 'arxivorgab', 'keskar', 'nitish', 'shirish', 'dheevatsa', 'mudiger', 'jorg', 'noced', 'mikhail', 'smelyanskiy', 'ping', 'tak', 'peter', 'tang', 'largebatch', 'train', 'deep', 'learn', 'gener', 'gap', 'sharp', 'minima', 'proceed', 'iclr', '2017', 'url', 'http', 'arxivorgab', 'krizhevski', 'alex', 'one', 'weird', 'trick', 'parallel', 'convolut', 'neural', 'network', 'corr', 'ab', '2014', 'url', 'http', 'arxivorgab', 'lee', 'jason', 'kyunghyun', 'cho', 'thoma', 'hofmann', 'fulli', 'characterlevel', 'neural', 'machin', 'translat', 'without', 'explicit', 'segment', 'corr', '2016', 'url', 'http', 'arxivorgab', '03017', 'lei', 'ba', 'j', 'j', 'r', 'kiro', 'g', 'e', 'hinton', 'layer', 'normal', 'arxiv', 'eprint', 'juli', '2016', 'papineni', 'kishor', 'salim', 'rouko', 'todd', 'ward', 'weij', 'zhu', 'bleu', 'method', 'au', 'tomat', 'evalu', 'machin', 'translat', 'proceed', 'acl', '2002', 'page', '311318', 'philadelphia', 'pennsylvania', '2002', 'popov', 'maja', 'chrf', 'characterngramfscoreforautomaticmtevalu', 'proceedingsofth', 'tenthworkshoponstatisticalmachinetransl', 'page', 'lisbon', 'portug', 'septemb', '2015', 'acl', 'url', 'http', 'aclweborganthologyw', 'sennrich', 'rico', 'barri', 'haddow', 'alexandra', 'birch', 'neural', 'machin', 'translat', 'rare', 'word', 'with', 'subword', 'unit', 'proceed', 'acl', '2016', 'page', '17151725', 'berlin', 'germani', 'august', '2016', 'acl', 'url', 'http', 'wwwaclweborganthologyp', 'shazeer', 'n', 'm', 'stern', 'adafactor', 'adapt', 'learn', 'rate', 'with', 'sublinear', 'memori', 'cost', 'arxiv', 'eprint', 'apr', '2018', 'url', 'http', 'arxivorgab', 'smith', 'samuel', 'l', 'quoc', 'v', 'le', 'bayesian', 'perspect', 'gener', 'stochast', 'gradient', 'descent', 'proceed', 'second', 'workshop', 'bayesian', 'deep', 'learn', 'nip', '2017', 'long', 'beach', 'ca', 'usa', '2017', 'url', 'http', 'arxivorgab', 'smith', 'samuel', 'l', 'pieterjan', 'kinderman', 'quoc', 'v', 'le', 'don', 't', 'decay', 'learn', 'rate', 'increas', 'batch', 'size', 'corr', '2017', 'url', 'http', 'arxivorgab', 'vaswani', 'ashish', 'noam', 'shazeer', 'niki', 'parmar', 'jakob', 'uszkoreit', 'llion', 'jone', 'aidan', 'n', 'gomez', 'lukaszkais', 'andilliapolosukhin', 'attentionisallyoune', 'inguyon', 'i', 'uvluxburg', 's', 'bengio', 'h', 'wallach', 'r', 'fergu', 's', 'vishwanathan', 'r', 'garnett', 'editor', 'advanc', 'neural', 'inform', 'process', 'system', '30', 'page', '60006010', 'curran', 'associ', 'inc', '2017', 'url', 'http', 'papersnipsccpaperattentionisallyouneedpdf', 'wu', 'yonghui', 'mike', 'schuster', 'zhifeng', 'chen', 'quoc', 'v', 'le', 'mohammad', 'norouzi', 'wolfgang', 'macherey', 'maximkrikun', 'yuancao', 'qingao', 'klausmacherey', 'je', 'klingner', 'apurvashah', 'melvinjohnson', 'xiaobingliu', 'lukaszkais', 'stephangouw', 'yoshikiyokato', 'takukudo', 'hidetokazawa', 'keithsteven', 'georgekurian', 'nishantpatil', 'weiwang', 'cli', 'young', 'jason', 'smith', 'jasonriesa', 'alexrudnick', 'oriolviny', 'gregcorrado', 'macdu', 'hugh', 'andj', 'rey', 'dean', 'googl', 'sneuralmachinetranslationsystem', 'bridgingthegapbetweenhumanand', 'machinetransl', 'corr', 'ab', 'url', 'http', 'arxivorgab', 'you', 'yang', 'igor', 'gitman', 'bori', 'ginsburg', 'scale', 'sgd', 'batch', 'size', 'k', 'imagenet', 'train', 'corr', 'ab', '2017', 'url', 'http', 'arxivorgab', 'address', 'correspond', 'martin', 'popel', 'popel', 'ufalmffcunicz', 'institut', 'formal', 'appli', 'linguist', 'faculti', 'mathemat', 'physic', 'charl', 'univers', 'malostransk', 'nmest', '25', '118', '00', 'praha', '1', 'czech', 'republ', '28']